{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECMM426_ECMM441_Feature_Description_and_Matching.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dannyburleigh/University/blob/main/ECMM426_ECMM441_Feature_Description_and_Matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3cZDcELRx4J"
      },
      "source": [
        "<H1 style=\"text-align: center\">ECMM426 - Computer Vision / ECMM441 - Machine Vision (Professional)</H1>\n",
        "<H1 style=\"text-align: center\"></H1>\n",
        "<H2 style=\"text-align: center\">Workshop 3</H2>\n",
        "<H2 style=\"text-align: center\">Feature Description and Matching</H2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szCE5_XbWDuS"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9pE0N3qRwOt"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import urllib\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import corner_peaks\n",
        "plt.rcParams['figure.figsize'] = (20.0, 10.0)\n",
        "plt.rcParams['figure.dpi'] = 72\n",
        "\n",
        "# install and then import opencv\n",
        "!pip3 install opencv-python==4.4.0.42\n",
        "import cv2\n",
        "print('OpenCV version: {}'.format(cv2.__version__))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VOwRMc2DLjT"
      },
      "source": [
        "if not os.path.exists('paired_data.zip'):\n",
        "    !wget --no-check-certificate https://empslocal.ex.ac.uk/people/staff/ad735/ECMM426/paired_data.zip\n",
        "    !unzip -q paired_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq1SSq7ZFnnW"
      },
      "source": [
        "## Utils\n",
        "Some useful functions that we are going to use this workshop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCUby-hQcjMN"
      },
      "source": [
        "import pickle\n",
        "def im2single(im):\n",
        "    im = im.astype(np.float32) / 255\n",
        "    return im\n",
        "\n",
        "def single2im(im):\n",
        "    im *= 255\n",
        "    im = im.astype(np.uint8)\n",
        "    return im\n",
        "\n",
        "def cheat_interest_points(eval_file, scale_factor):\n",
        "    \"\"\"\n",
        "    This function is provided for development and debugging but cannot be used in\n",
        "    the final handin. It 'cheats' by generating interest points from known\n",
        "    correspondences. It will only work for the 3 image pairs with known\n",
        "    correspondences.\n",
        "\n",
        "    Args:\n",
        "    - eval_file: string representing the file path to the list of known correspondences\n",
        "    - scale_factor: Python float representing the scale needed to map from the original\n",
        "            image coordinates to the resolution being used for the current experiment.\n",
        "\n",
        "    Returns:\n",
        "    - x1: A numpy array of shape (k,) containing ground truth x-coordinates of imgA correspondence pts\n",
        "    - y1: A numpy array of shape (k,) containing ground truth y-coordinates of imgA correspondence pts\n",
        "    - x2: A numpy array of shape (k,) containing ground truth x-coordinates of imgB correspondence pts\n",
        "    - y2: A numpy array of shape (k,) containing ground truth y-coordinates of imgB correspondence pts\n",
        "    \"\"\"\n",
        "    with open(eval_file, 'rb') as f:\n",
        "        d = pickle.load(f, encoding='latin1')\n",
        "\n",
        "    return d['x1'] * scale_factor, d['y1'] * scale_factor, d['x2'] * scale_factor,\\\n",
        "                    d['y2'] * scale_factor\n",
        "\n",
        "def show_interest_points(img, X, Y):\n",
        "    \"\"\"\n",
        "    Visualized interest points on an image with random colors\n",
        "\n",
        "    Args:\n",
        "    - img: A numpy array of shape (M,N,C)\n",
        "    - X: A numpy array of shape (k,) containing x-locations of interest points\n",
        "    - Y: A numpy array of shape (k,) containing y-locations of interest points\n",
        "\n",
        "    Returns:\n",
        "    - newImg: A numpy array of shape (M,N,C) showing the original image with\n",
        "            colored circles at keypoints plotted on top of it\n",
        "    \"\"\"\n",
        "    radius_circle = 20\n",
        "    newImg = img.copy()\n",
        "    for x, y in zip(X.astype(int), Y.astype(int)):\n",
        "        cur_color = np.random.rand(3)\n",
        "        newImg = cv2.circle(newImg, (x, y), radius_circle, cur_color, -1, cv2.LINE_AA)\n",
        "    return newImg\n",
        "\n",
        "def show_correspondence_circles(imgA, imgB, X1, Y1, X2, Y2):\n",
        "    \"\"\"\n",
        "    Visualizes corresponding points between two images by plotting circles at\n",
        "    each correspondence location. Corresponding points will have the same random color.\n",
        "\n",
        "    Args:\n",
        "    - imgA: A numpy array of shape (M,N,3)\n",
        "    - imgB: A numpy array of shape (D,E,3)\n",
        "    - x1: A numpy array of shape (k,) containing x-locations of keypoints in imgA\n",
        "    - y1: A numpy array of shape (k,) containing y-locations of keypoints in imgA\n",
        "    - x2: A numpy array of shape (j,) containing x-locations of keypoints in imgB\n",
        "    - y2: A numpy array of shape (j,) containing y-locations of keypoints in imgB\n",
        "\n",
        "    Returns:\n",
        "    - newImg: A numpy array of shape (max(M,D), N+E, 3)\n",
        "    \"\"\"\n",
        "    radius_circle = 20\n",
        "    newImg = hstack_images(imgA, imgB)\n",
        "    shiftX = imgA.shape[1]\n",
        "    X1 = X1.astype(np.int)\n",
        "    Y1 = Y1.astype(np.int)\n",
        "    X2 = X2.astype(np.int)\n",
        "    Y2 = Y2.astype(np.int)\n",
        "\n",
        "    for x1, y1, x2, y2 in zip(X1, Y1, X2, Y2):\n",
        "        cur_color = np.random.rand(3)\n",
        "        green = (0, 1, 0)\n",
        "        newImg = cv2.circle(newImg, (x1, y1), radius_circle, cur_color, -1, cv2.LINE_AA)\n",
        "        newImg = cv2.circle(newImg, (x1, y1), radius_circle, green, 2, cv2.LINE_AA)\n",
        "        newImg = cv2.circle(newImg, (x2+shiftX, y2), radius_circle, cur_color, -1, cv2.LINE_AA)\n",
        "        newImg = cv2.circle(newImg, (x2+shiftX, y2), radius_circle, green, 2, cv2.LINE_AA)\n",
        "\n",
        "    return newImg\n",
        "\n",
        "def show_correspondence_lines(imgA, imgB, X1, Y1, X2, Y2, line_colors=None):\n",
        "    \"\"\"\n",
        "    Visualizes corresponding points between two images by drawing a line segment\n",
        "    between the two images for each (x1,y1) (x2,y2) pair.\n",
        "\n",
        "    Args:\n",
        "    - imgA: A numpy array of shape (M,N,3)\n",
        "    - imgB: A numpy array of shape (D,E,3)\n",
        "    - x1: A numpy array of shape (k,) containing x-locations of keypoints in imgA\n",
        "    - y1: A numpy array of shape (k,) containing y-locations of keypoints in imgA\n",
        "    - x2: A numpy array of shape (j,) containing x-locations of keypoints in imgB\n",
        "    - y2: A numpy array of shape (j,) containing y-locations of keypoints in imgB\n",
        "    - line_colors: A numpy array of shape (N x 3) with colors of correspondence lines (optional)\n",
        "\n",
        "    Returns:\n",
        "    - newImg: A numpy array of shape (max(M,D), N+E, 3)\n",
        "    \"\"\"\n",
        "    radius_circle = 20\n",
        "    newImg = hstack_images(imgA, imgB)\n",
        "    shiftX = imgA.shape[1]\n",
        "    X1 = X1.astype(np.int)\n",
        "    Y1 = Y1.astype(np.int)\n",
        "    X2 = X2.astype(np.int)\n",
        "    Y2 = Y2.astype(np.int)\n",
        "\n",
        "    dot_colors = np.random.rand(len(X1), 3)\n",
        "    if line_colors is None:\n",
        "        line_colors = dot_colors\n",
        "\n",
        "    for x1, y1, x2, y2, dot_color, line_color in zip(X1, Y1, X2, Y2, dot_colors, line_colors):\n",
        "        newImg = cv2.circle(newImg, (x1, y1), radius_circle, dot_color, -1)\n",
        "        newImg = cv2.circle(newImg, (x2+shiftX, y2), radius_circle, dot_color, -1)\n",
        "        newImg = cv2.line(newImg, (x1, y1), (x2+shiftX, y2), line_color, 2, cv2.LINE_AA)\n",
        "    return newImg\n",
        "\n",
        "def hstack_images(imgA, imgB):\n",
        "    \"\"\"\n",
        "    Stacks 2 images side-by-side and creates one combined image.\n",
        "\n",
        "    Args:\n",
        "    - imgA: A numpy array of shape (M,N,3) representing rgb image\n",
        "    - imgB: A numpy array of shape (D,E,3) representing rgb image\n",
        "\n",
        "    Returns:\n",
        "    - newImg: A numpy array of shape (max(M,D), N+E, 3)\n",
        "    \"\"\"\n",
        "    Height = max(imgA.shape[0], imgB.shape[0])\n",
        "    Width  = imgA.shape[1] + imgB.shape[1]\n",
        "\n",
        "    newImg = np.zeros((Height, Width, 3), dtype=imgA.dtype)\n",
        "    newImg[:imgA.shape[0], :imgA.shape[1], :] = imgA\n",
        "    newImg[:imgB.shape[0], imgA.shape[1]:, :] = imgB\n",
        "\n",
        "    return newImg\n",
        "\n",
        "def evaluate_correspondence(imgA, imgB, corr_fpath, scale_factor, x1_est, y1_est,\n",
        "        x2_est, y2_est, confidences=None, num_req_matches=100):\n",
        "    \"\"\"\n",
        "    Function to evaluate estimated correspondences against ground truth.\n",
        "\n",
        "    The evaluation requires 100 matches to receive full credit\n",
        "    when num_req_matches=100 because we define accuracy as:\n",
        "\n",
        "    Accuracy = (true_pos)/(true_pos+false_pos) * min(num_matches,num_req_matches)/num_req_matches\n",
        "\n",
        "    Args:\n",
        "    - imgA: A numpy array of shape (M,N,C) representing a first image\n",
        "    - imgB: A numpy array of shape (M,N,C) representing a second image\n",
        "    - corr_fpath: string, representing a filepath to a .pkl file containing ground truth correspondences\n",
        "    - scale_factor: scale factor on the size of the images\n",
        "    - x1_est: A numpy array of shape (k,) containing estimated x-coordinates of imgA correspondence pts\n",
        "    - y1_est: A numpy array of shape (k,) containing estimated y-coordinates of imgA correspondence pts\n",
        "    - x2_est: A numpy array of shape (k,) containing estimated x-coordinates of imgB correspondence pts\n",
        "    - y2_est: A numpy array of shape (k,) containing estimated y-coordinates of imgB correspondence pts\n",
        "    - confidences: (optional) confidence values in the matches\n",
        "    \"\"\"\n",
        "    if confidences is None:\n",
        "        confidences = np.random.rand(len(x1_est))\n",
        "        confidences /= np.max(confidences)\n",
        "\n",
        "    x1_est = x1_est.squeeze() / scale_factor\n",
        "    y1_est = y1_est.squeeze() / scale_factor\n",
        "    x2_est = x2_est.squeeze() / scale_factor\n",
        "    y2_est = y2_est.squeeze() / scale_factor\n",
        "\n",
        "    num_matches = x1_est.shape[0]\n",
        "\n",
        "    x1,y1,x2,y2 = load_corr_pkl_file(corr_fpath)\n",
        "\n",
        "    good_matches = [False for _ in range(len(x1_est))]\n",
        "    # array marking which GT pairs are already matched\n",
        "    matched = [False for _ in range(len(x1))]\n",
        "\n",
        "    # iterate through estimated pairs in decreasing order of confidence\n",
        "    priority = np.argsort(-confidences)\n",
        "    for i in priority:\n",
        "        # print('Examining ({:4.0f}, {:4.0f}) to ({:4.0f}, {:4.0f})'.format(\n",
        "        #     x1_est[i], y1_est[i], x2_est[i], y2_est[i]))\n",
        "        cur_offset = np.asarray([x1_est[i]-x2_est[i], y1_est[i]-y2_est[i]])\n",
        "        # for each x1_est find nearest ground truth point in x1\n",
        "        dists = np.linalg.norm(np.vstack((x1_est[i]-x1, y1_est[i]-y1)), axis=0)\n",
        "        best_matches = np.argsort(dists)\n",
        "\n",
        "        # find the best match that is not taken yet\n",
        "        for match_idx in best_matches:\n",
        "            if not matched[match_idx]:\n",
        "                break\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # A match is good only if\n",
        "        # (1) An unmatched GT point exists within 150 pixels, and\n",
        "        # (2) GT correspondence offset is within 25 pixels of estimated\n",
        "        #     correspondence offset\n",
        "        gt_offset = np.asarray([x1[match_idx]-x2[match_idx],\n",
        "            y1[match_idx]-y2[match_idx]])\n",
        "        offset_dist = np.linalg.norm(cur_offset-gt_offset)\n",
        "        if (dists[match_idx] < 150.0) and (offset_dist < 25):\n",
        "            good_matches[i] = True\n",
        "            print('Correct')\n",
        "        else:\n",
        "            print('Incorrect')\n",
        "\n",
        "    print('You found {}/{} required matches'.format(num_matches, num_req_matches))\n",
        "    accuracy = np.mean(good_matches) * min(num_matches, num_req_matches)*1./num_req_matches\n",
        "    print('Accuracy = {:f}'.format(accuracy))\n",
        "    green = np.asarray([0, 1, 0], dtype=float)\n",
        "    red = np.asarray([1, 0, 0], dtype=float)\n",
        "    line_colors = np.asarray([green if m else red for m in good_matches])\n",
        "\n",
        "    return accuracy, show_correspondence_lines(imgA, imgB,\n",
        "                                               x1_est*scale_factor, y1_est*scale_factor,\n",
        "                                               x2_est*scale_factor, y2_est*scale_factor,\n",
        "                                               line_colors)\n",
        "\n",
        "def load_corr_pkl_file(corr_fpath):\n",
        "    \"\"\" \n",
        "    Load ground truth correspondences from a pickle (.pkl) file. \n",
        "    \"\"\"\n",
        "    with open(corr_fpath, 'rb') as f:\n",
        "        d = pickle.load(f, encoding='latin1')\n",
        "    x1 = d['x1'].squeeze()\n",
        "    y1 = d['y1'].squeeze()\n",
        "    x2 = d['x2'].squeeze()\n",
        "    y2 = d['y2'].squeeze()\n",
        "\n",
        "    return x1,y1,x2,y2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30lS4TG2DJB9"
      },
      "source": [
        "## Get some paired data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkiG0NDcHpFD"
      },
      "source": [
        "### Notre Dame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iSHATrfDVm3"
      },
      "source": [
        "scale_factor = 1.0\n",
        "img1 = im2single(cv2.cvtColor(cv2.imread('paired_data/Notre Dame/921919841_a30df938f2_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "img1 = cv2.resize(img1, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "img2 = im2single(cv2.cvtColor(cv2.imread('paired_data/Notre Dame/4191453057_c86028ce1f_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "img2 = cv2.resize(img2, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "eval_file = 'paired_data/Notre Dame/921919841_a30df938f2_o_to_4191453057_c86028ce1f_o.pkl'\n",
        "x1, y1, x2, y2 = cheat_interest_points(eval_file, scale_factor)\n",
        "c1 = show_interest_points(img1, x1, y1)\n",
        "c2 = show_interest_points(img2, x2, y2)\n",
        "plt.subplot(1, 2, 1), plt.imshow(c1)\n",
        "plt.subplot(1, 2, 2), plt.imshow(c2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U3j1r14HtDC"
      },
      "source": [
        "###Mount Rushmore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "neVYlAPiGwJP"
      },
      "source": [
        "scale_factor = 1.0\n",
        "img1 = im2single(cv2.cvtColor(cv2.imread('paired_data/Mount Rushmore/9021235130_7c2acd9554_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "img1 = cv2.resize(img1, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "img2 = im2single(cv2.cvtColor(cv2.imread('paired_data/Mount Rushmore/9318872612_a255c874fb_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "img2 = cv2.resize(img2, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "eval_file = 'paired_data/Mount Rushmore/9021235130_7c2acd9554_o_to_9318872612_a255c874fb_o.pkl'\n",
        "x1, y1, x2, y2 = cheat_interest_points(eval_file, scale_factor)\n",
        "c1 = show_interest_points(img1, x1, y1)\n",
        "c2 = show_interest_points(img2, x2, y2)\n",
        "plt.subplot(1, 2, 1), plt.imshow(c1)\n",
        "plt.subplot(1, 2, 2), plt.imshow(c2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWVh3KhbHzYZ"
      },
      "source": [
        "###Episcopal Gaudi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDtSxS5eHKW6"
      },
      "source": [
        "scale_factor = 1.0\n",
        "img1 = im2single(cv2.cvtColor(cv2.imread('paired_data/Episcopal Gaudi/4386465943_8cf9776378_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "img1 = cv2.resize(img1, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "img2 = im2single(cv2.cvtColor(cv2.imread('paired_data/Episcopal Gaudi/3743214471_1b5bbfda98_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "img2 = cv2.resize(img2, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "eval_file = 'paired_data/Episcopal Gaudi/4386465943_8cf9776378_o_to_3743214471_1b5bbfda98_o.pkl'\n",
        "x1, y1, x2, y2 = cheat_interest_points(eval_file, scale_factor)\n",
        "c1 = show_interest_points(img1, x1, y1)\n",
        "c2 = show_interest_points(img2, x2, y2)\n",
        "plt.subplot(1, 2, 1), plt.imshow(c1)\n",
        "plt.subplot(1, 2, 2), plt.imshow(c2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx7gKdFFDCmr"
      },
      "source": [
        "## `NormalizedPatchFeatures` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL02rdhgLIoY"
      },
      "source": [
        "def NormalizedPatchFeatures(img, x, y, feature_width=16, scales=None):\n",
        "    assert img.ndim == 2, 'Image must be grayscale'\n",
        "\n",
        "    # Gaussian smoothing\n",
        "    img = cv2.GaussianBlur(img, (3, 3), 2)\n",
        "\n",
        "    # allocate memory\n",
        "    features = np.zeros((x.shape[0], feature_width**2))\n",
        "    \n",
        "    # half of feature width\n",
        "    win_rng = feature_width // 2\n",
        "\n",
        "    # go through each key point\n",
        "    for i in range(x.shape[0]):\n",
        "        xi = int(x[i])\n",
        "        yi = int(y[i])\n",
        "        # get patch\n",
        "        patch = img[yi - win_rng : yi + win_rng, xi - win_rng : xi + win_rng]\n",
        "        features[i, :] = patch.flatten()\n",
        "    features = features**0.5\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmU2xBJvIErc"
      },
      "source": [
        "## Matching with ratio criteria"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8FP2SxdKMsl"
      },
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "def MatchFeatures(features1, features2, x1, y1, x2, y2, threshold=0.75):\n",
        "\n",
        "    # euclidean distances\n",
        "    distances = euclidean_distances(features1, features2)\n",
        "\n",
        "    # sorted distances\n",
        "    indices = np.argsort(distances, axis=1)\n",
        "    sorted_distances = np.take_along_axis(distances, indices, axis=1)\n",
        "\n",
        "    # NNDR\n",
        "    scores = sorted_distances[:, 0] / sorted_distances[:, 1]\n",
        "\n",
        "    # where scores < threshold\n",
        "    idx = scores < threshold\n",
        "\n",
        "    # confidence\n",
        "    confidences = 1 / scores[idx]\n",
        "\n",
        "    k = confidences.shape[0]\n",
        "    matches = np.zeros((k, 2), dtype=int)\n",
        "    \n",
        "    # matches for which we have score or distance < threshold\n",
        "    matches[:, 0] = np.where(idx)[0]\n",
        "    matches[:, 1] = indices[idx, 0]\n",
        "\n",
        "    # arrange the matches and the confidences in descending order\n",
        "    idx = (-confidences).argsort()\n",
        "    matches = matches[idx, :]\n",
        "    confidences = confidences[idx]\n",
        "\n",
        "    return matches, confidences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-VdvxHmb0tY"
      },
      "source": [
        "## Notre Dame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsIeFwkBFxX4"
      },
      "source": [
        "scale_factor = 1.0\n",
        "img1 = im2single(cv2.cvtColor(cv2.imread('paired_data/Notre Dame/921919841_a30df938f2_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "img1 = cv2.resize(img1, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "img2 = im2single(cv2.cvtColor(cv2.imread('paired_data/Notre Dame/4191453057_c86028ce1f_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "img2 = cv2.resize(img2, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "eval_file = 'paired_data/Notre Dame/921919841_a30df938f2_o_to_4191453057_c86028ce1f_o.pkl'\n",
        "x1, y1, x2, y2 = cheat_interest_points(eval_file, scale_factor)\n",
        "gray_img1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "gray_img2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
        "img1_feats = NormalizedPatchFeatures(gray_img1, x1, y1)\n",
        "img2_feats = NormalizedPatchFeatures(gray_img2, x2, y2)\n",
        "matches, confidences = MatchFeatures(img1_feats, img2_feats, x1, y1, x2, y2, threshold=0.95)\n",
        "print('{:d} matches from {:d} corners'.format(len(matches), len(x1)))\n",
        "num_pts_to_evaluate = 100\n",
        "_, c = evaluate_correspondence(img1, img2, eval_file, scale_factor,\n",
        "                        x1[matches[:num_pts_to_evaluate, 0]], y1[matches[:num_pts_to_evaluate, 0]],\n",
        "                        x2[matches[:num_pts_to_evaluate, 1]], y2[matches[:num_pts_to_evaluate, 1]])\n",
        "plt.figure(); plt.imshow(c)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIw8q8RAFTUS"
      },
      "source": [
        "## Mount Rushmore"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7L_DHYlj1Qi"
      },
      "source": [
        "img1 = im2single(cv2.cvtColor(cv2.imread('paired_data/Mount Rushmore/9021235130_7c2acd9554_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "img2 = im2single(cv2.cvtColor(cv2.imread('paired_data/Mount Rushmore/9318872612_a255c874fb_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "eval_file = 'paired_data/Mount Rushmore/9021235130_7c2acd9554_o_to_9318872612_a255c874fb_o.pkl'\n",
        "img1 = cv2.resize(img1, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "img2 = cv2.resize(img2, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "x1, y1, x2, y2 = cheat_interest_points(eval_file, scale_factor)\n",
        "gray_img1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "gray_img2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
        "img1_feats = NormalizedPatchFeatures(gray_img1, x1, y1)\n",
        "img2_feats = NormalizedPatchFeatures(gray_img2, x2, y2)\n",
        "matches, confidences = MatchFeatures(img1_feats, img2_feats, x1, y1, x2, y2, threshold=1.0)\n",
        "print('{:d} matches from {:d} corners'.format(len(matches), len(x1)))\n",
        "num_pts_to_evaluate = 100\n",
        "_, c = evaluate_correspondence(img1, img2, eval_file, scale_factor,\n",
        "                        x1[matches[:num_pts_to_evaluate, 0]], y1[matches[:num_pts_to_evaluate, 0]],\n",
        "                        x2[matches[:num_pts_to_evaluate, 1]], y2[matches[:num_pts_to_evaluate, 1]])\n",
        "plt.figure(); plt.imshow(c)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8jxJsOdFZL7"
      },
      "source": [
        "## Episcopal Gaudi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb6mdn4o9ZxM"
      },
      "source": [
        "img1 = im2single(cv2.cvtColor(cv2.imread('paired_data/Episcopal Gaudi/4386465943_8cf9776378_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "img2 = im2single(cv2.cvtColor(cv2.imread('paired_data/Episcopal Gaudi/3743214471_1b5bbfda98_o.jpg'), cv2.COLOR_BGR2RGB))\n",
        "eval_file = 'paired_data/Episcopal Gaudi/4386465943_8cf9776378_o_to_3743214471_1b5bbfda98_o.pkl'\n",
        "img1 = cv2.resize(img1, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "img2 = cv2.resize(img2, (0, 0), fx=scale_factor, fy=scale_factor)\n",
        "x1, y1, x2, y2 = cheat_interest_points(eval_file, scale_factor)\n",
        "gray_img1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "gray_img2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)\n",
        "img1_feats = NormalizedPatchFeatures(gray_img1, x1, y1)\n",
        "img2_feats = NormalizedPatchFeatures(gray_img2, x2, y2)\n",
        "matches, confidences = MatchFeatures(img1_feats, img2_feats, x1, y1, x2, y2, threshold=1.0)\n",
        "print('{:d} matches from {:d} corners'.format(len(matches), len(x1)))\n",
        "num_pts_to_evaluate = 100\n",
        "_, c = evaluate_correspondence(img1, img2, eval_file, scale_factor,\n",
        "                        x1[matches[:num_pts_to_evaluate, 0]], y1[matches[:num_pts_to_evaluate, 0]],\n",
        "                        x2[matches[:num_pts_to_evaluate, 1]], y2[matches[:num_pts_to_evaluate, 1]])\n",
        "plt.figure(); plt.imshow(c)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-smEeAz_Wfa"
      },
      "source": [
        "## SIFT like features\n",
        "Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8AOF97FrJjr"
      },
      "source": [
        "# convert one image to gray image\n",
        "gray_img1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "# get sobel filters\n",
        "I_x = cv2.Sobel(gray_img1, cv2.CV_64F, 1, 0, ksize=3)\n",
        "I_y = cv2.Sobel(gray_img1, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "# compute angles and magnitudes of the image\n",
        "angles = np.arctan2(I_y, I_x)\n",
        "magnitudes = np.sqrt(I_x ** 2 + I_y ** 2)\n",
        "\n",
        "print('maximum of angles: {0}, minimum of angles: {1}, maximum of magnitudes: {2}, minimum of magnitudes: {3}'\n",
        ".format(np.max(angles), np.min(angles), np.max(magnitudes), np.min(magnitudes)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwMi4OBEwKmK"
      },
      "source": [
        "# plot\n",
        "plt.subplot(1, 2, 1); plt.imshow(angles, cmap='gray')\n",
        "plt.title('Angles')\n",
        "plt.subplot(1, 2, 2); plt.imshow(magnitudes, cmap='gray')\n",
        "plt.title('Magnitudes')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmjNVGDtsdiW"
      },
      "source": [
        "# any random interest point\n",
        "idx = np.random.randint(x1.shape[0])\n",
        "\n",
        "# coordinate\n",
        "xi = int(x1[idx])\n",
        "yi = int(y1[idx])\n",
        "\n",
        "half_win_rng = 8\n",
        "\n",
        "# get patch\n",
        "angles_patch = angles[yi - half_win_rng : yi + half_win_rng, xi - half_win_rng : xi + half_win_rng]\n",
        "magnitudes_patch = magnitudes[yi - half_win_rng : yi + half_win_rng, xi - half_win_rng : xi + half_win_rng]\n",
        "\n",
        "# plot\n",
        "plt.subplot(1, 2, 1); plt.imshow(angles_patch, cmap='gray')\n",
        "plt.title('Angles patch')\n",
        "plt.subplot(1, 2, 2); plt.imshow(magnitudes_patch, cmap='gray')\n",
        "plt.title('Magnitudes patch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzIRtfLuyCdS"
      },
      "source": [
        "feature_width = 16\n",
        "step = 4\n",
        "count = 1\n",
        "for j in range(0, feature_width, step):\n",
        "    for k in range(0, feature_width, step):\n",
        "        # get bins for each patch\n",
        "        angles_patch_bin = angles_patch[j : j + 4, k : k + 4]\n",
        "        magnitudes_patch_bin = magnitudes_patch[j : j + 4, k : k + 4]\n",
        "        # plot\n",
        "        plt.subplot(1, 2, 1); plt.imshow(angles_patch_bin, cmap='gray')\n",
        "        plt.title('Angles bin for patch ' + str(count))\n",
        "        plt.subplot(1, 2, 2); plt.imshow(magnitudes_patch_bin, cmap='gray')\n",
        "        plt.title('Magnitudes bin for patch ' + str(count))\n",
        "        plt.show()\n",
        "        count += 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}